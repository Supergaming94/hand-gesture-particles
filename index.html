<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Final Particle Fix</title>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: sans-serif; }
        #status { position: absolute; top: 10px; left: 10px; color: #0f0; background: rgba(0,0,0,0.8); padding: 10px; font-size: 14px; z-index: 100; border: 1px solid #444; }
        video { transform: scaleX(-1); position: absolute; top: 10px; right: 10px; width: 80px; height: 60px; border: 1px solid #444; opacity: 0.1; }
    </style>
</head>
<body>
    <div id="status">Loading...</div>
    <video id="webcam" autoplay playsinline muted></video>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <script>
        const statusEl = document.getElementById('status');
        const videoElement = document.getElementById('webcam');
        let scene, camera, renderer, particles, material;

        function init() {
            scene = new THREE.Scene();
            // Using an Orthographic Camera makes 2D tracking much easier to see
            const aspect = window.innerWidth / window.innerHeight;
            const d = 30;
            camera = new THREE.OrthographicCamera(-d * aspect, d * aspect, d, -d, 1, 1000);
            camera.position.z = 100;

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            const count = 4000;
            const geo = new THREE.BufferGeometry();
            const indices = new Float32Array(count);
            for (let i = 0; i < count; i++) indices[i] = i;
            geo.setAttribute('aIndex', new THREE.BufferAttribute(indices, 1));

            material = new THREE.ShaderMaterial({
                uniforms: {
                    uTime: { value: 0 },
                    uExpand: { value: 0.8 },
                    uTemplate: { value: 0 }
                },
                vertexShader: `
                    uniform float uTime;
                    uniform float uExpand;
                    uniform float uTemplate;
                    attribute float aIndex;
                    varying vec3 vColor;
                    void main() {
                        float i = aIndex / 4000.0;
                        float a = i * 6.28318;
                        vec3 p = vec3(0.0);
                        
                        if(uTemplate < 0.5) { // Heart
                            p.x = 16.0*pow(sin(a),3.0);
                            p.y = 13.0*cos(a)-5.0*cos(2.0*a)-2.0*cos(3.0*a)-cos(4.0*a);
                        } else if(uTemplate < 1.5) { // Flower
                            float r = 12.0 + 4.0*sin(a*6.0);
                            p.x = r*cos(a); p.y = r*sin(a);
                        } else { // Circle
                            p.x = 20.0*cos(a); p.y = 20.0*sin(a);
                        }

                        p *= (0.4 + uExpand * 1.5);
                        vColor = vec3(0.0, 1.0, 1.0); 
                        vec4 mv = modelViewMatrix * vec4(p, 1.0);
                        gl_PointSize = 12.0; // Huge points
                        gl_Position = projectionMatrix * mv;
                    }
                `,
                fragmentShader: `
                    varying vec3 vColor;
                    void main() {
                        if(length(gl_PointCoord - 0.5) > 0.5) discard;
                        gl_FragColor = vec4(vColor, 1.0);
                    }
                `
            });

            particles = new THREE.Points(geo, material);
            scene.add(particles);
            
            animate();
            startCamera();
        }

        function animate() {
            requestAnimationFrame(animate);
            if(material) material.uniforms.uTime.value += 0.05;
            renderer.render(scene, camera);
        }

        function startCamera() {
            const hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({ maxNumHands: 1, modelComplexity: 0 });

            hands.onResults((res) => {
                if (res.multiHandLandmarks && res.multiHandLandmarks.length > 0) {
                    statusEl.innerText = "TRACKING ACTIVE";
                    const lm = res.multiHandLandmarks[0];
                    
                    // Orthographic mapping is 1:1
                    const aspect = window.innerWidth / window.innerHeight;
                    const x = (lm[9].x - 0.5) * -60 * aspect; 
                    const y = (lm[9].y - 0.5) * -60;
                    
                    particles.position.set(x, y, 0);

                    const dist = Math.hypot(lm[4].x - lm[8].x, lm[4].y - lm[8].y);
                    material.uniforms.uExpand.value = dist * 2.0;
                } else {
                    statusEl.innerText = "Searching for hand...";
                    particles.position.set(0,0,0); // Reset to center
                }
            });

            const cam = new Camera(videoElement, {
                onFrame: async () => { await hands.send({image: videoElement}); },
                width: 640, height: 480
            });
            cam.start();
        }

        window.onload = init;
    </script>
</body>
</html>
